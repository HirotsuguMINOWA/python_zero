<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>

<style>
    .btn-square {
      display: inline-block;
      padding: 0.5em 0.5em;
      text-decoration: none;
      background: #668ad8;
      color: #FFF;
      border-bottom: solid 4px #626295;
      border-radius: 5px;
    }

    .btn-square:active {
      -webkit-transform: translateY(4px);
      transform: translateY(4px);
      border-bottom: none;
    }
  .markdown-body {
    box-sizing: border-box;
    min-width: 200px;
    max-width: 980px;
    margin: 0 auto;
    padding: 45px;
  }
  p.caption{
    display:none;
  }
  img {width: 100%}

  @media (max-width: 767px) {
    .markdown-body {
      padding: 15px;
    }
  }
</style>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://kaityo256.github.io/python_zero/github-markdown.css" type="text/css" />
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
<link href="https://use.fontawesome.com/releases/v5.6.1/css/all.css" rel="stylesheet">
</head>
<body>
<article class="markdown-body">
<h1 id="簡単な機械学習">簡単な機械学習</h1>
<p><a href="../index.html">[Up]</a> <a href="https://github.com/kaityo256/python_zero">[Repository]</a></p>
<h2 id="本講で学ぶこと">本講で学ぶこと</h2>
<ul>
<li>機械学習の概要</li>
<li>回帰</li>
<li>GAN</li>
</ul>
<h2 id="機械学習とは">機械学習とは</h2>
<p>昨今、「機械学習」「ディープラーニング」「AI」といった言葉をよく聞く。Googleによる機械学習のフレームワーク「TensorFlow」や、PFNによる「Chainer」などがPythonで記述されていることもあり、機械学習をする上でPythonが事実上の共通語になりつつある。機械学習による派手な結果を目にすることも多いだろう。せっかく本講義でPythonを学んだのであるから、最後は機械学習を体験してみよう。今回は、ざっと機械学習の概要について触れてから、機械学習で注目されている技術の一つ、GANによる画像生成を体験してみる。</p>
<h3 id="機械学習の種類">機械学習の種類</h3>
<p>一口に「機械学習」と言っても、機械学習がカバーする範囲は広い。現在も様々な技術が提案されているため、その全てを厳密に分類するのは難しいが、よく言われるのは以下の三種類の分類である。</p>
<ol style="list-style-type: decimal">
<li>教師あり学習</li>
<li>教師なし学習</li>
<li>強化学習</li>
</ol>
<p><strong>教師あり学習(Supervised Learning)</strong> とは、「問題と解答のセット」を与えて、それで学習させる方法である。例えば、予め大量の写真を用意し、それぞれに「ネコ」や「イヌ」といったラベルをつけておく。それを学習させることで、「学習に用いたデータセットに含まれていない、初めて見る写真」に対しても正しく「ネコ」や「イヌ」と判定できるようにさせるのが典型的な教師あり学習である。</p>
<p><strong>教師なし学習(Unsupervised Learning)</strong> とは、データだけを与えて、データを分類したり、似ているものを探したりさせる方法である。例えば物品の売上データを解析し、「ある商品Aを購入した人は、次は商品Bを購入する可能性が高い」といった関係を見つければ、商品Aを購入した人に「Bはいかがでしょうか？」と勧めることができ、売上向上につながる。オンラインショップなどでよく見る「この商品を買った人はこんな商品も買っています」というアレである。</p>
<p><strong>強化学習(Reinforcement Learning)</strong> とは、何かエージェントに行動をさせて、その結果として報酬を与えることで、「うまく」行動できるように学習させていく手法である。典型的な応用例はチェスや囲碁、将棋などのボードゲームのAIであろう。ある局面において、多数ある合法手の中から「次の一手」を選ばなければならない。この時、とりあえず(現在の知識で)適当に指してみて、勝負が決まってから振り返り、「最終的に勝利につながった手」に正の報酬を、「敗北につながった手」に負の報酬を与えることで、それぞれの局面において「これは良い手だった」「これは悪手だった」と学習していく。</p>
<p>これらはどれも面白く、それぞれ奥が深いのだが、ここでは教師あり学習に注目する。</p>
<p>「教師あり学習」が扱う問題は、さらに「分類問題」と「回帰問題」にわけることができる。分類問題とは、入力に対して有限のラベルのどれかを当てる問題である。例えば「ネコ」「イヌ」「ゾウ」「パンダ」のどれかが写っている写真を見せられ、何が写っているかを答えるのが典型的な分類問題である。特に、ラベルが「Yes」か「No」の二種類である時、これを二値分類問題と呼ぶ。回帰問題とは、入力に対して何か連続な値を返す問題である。例えば家の広さ、築年数、駅からの距離や周りの条件等から家賃を推定するのが典型的な回帰問題である。</p>
<h3 id="学習と最適化">学習と最適化</h3>
<p>機械学習では、よく「学習」という言葉が出てくる。学習とは、ある量を最適化することだ。その最適化の簡単な例として、線形回帰を見てよう。</p>
<p>回帰とは、何かしらの入力<span class="math inline">\(x\)</span>に対して、出力<span class="math inline">\(y\)</span>が得られる時、その間の関係<span class="math inline">\(y = f(x)\)</span>を推定する問題である。例えば片方を固定されたバネに荷重をかけ、どのくらい伸びるかを調べる実験を考える。この場合の入力<span class="math inline">\(x\)</span>は荷重、出力<span class="math inline">\(y\)</span>はバネの伸びである。とりあえずいくつか重りを乗せてみて、荷重と伸びの観測値をグラフにプロットしてみたら以下のようになったとしよう。</p>
<div class="figure">
<img src="fig/regression.png" alt="バネの伸びと荷重の関係" />
<p class="caption">バネの伸びと荷重の関係</p>
</div>
<p>ここから、バネ定数を推定するには最小二乗法を使えば良いことは知っているであろうが、簡単におさらいしておこう。いま、<span class="math inline">\(N\)</span>回異なる荷重をかける実験を行い、荷重とバネの伸びの観測値の組<span class="math inline">\((x_i, y_i)\)</span>が得られたとする。さて、フックの法則から<span class="math inline">\(y = a x\)</span>が予想される。<span class="math inline">\(x_i\)</span>の荷重がかかった時、このモデルによる予想値は<span class="math inline">\(a x_i\)</span>だが、観測値は<span class="math inline">\(y_i\)</span>だ。そのズレ<span class="math inline">\(y_i - a x_i\)</span>を残差と呼ぶ。この残差の二乗和は<span class="math inline">\(a\)</span>の関数であり、以下のように表すことができる。</p>
<p><span class="math display">\[
C(a) = \sum_i^N (a x_i - y_i)^2
\]</span></p>
<p><span class="math inline">\(C(a)\)</span>はモデルと観測値の誤差を表している。<span class="math inline">\(a\)</span>が大きすぎても小さすぎても<span class="math inline">\(C(a)\)</span>は大きくなるので、どこかに最適な<span class="math inline">\(a\)</span>があるだろう。<span class="math inline">\(C(a)\)</span>を最小化するような<span class="math inline">\(a\)</span>の値は、<span class="math inline">\(C(a)\)</span>を<span class="math inline">\(a\)</span>で微分してゼロになるような点であるはずだ。微分してみよう。</p>
<p><span class="math display">\[
\frac{dC}{da} = \sum_i^N (2 a x_i^2 - 2a x_i y_i) = 0
\]</span></p>
<p>これを<span class="math inline">\(a\)</span>について解けば、</p>
<p><span class="math display">\[
a = \frac{\sum_i^N x_i y_i}{\sum_i^N x_i^2}
\]</span></p>
<p>を得る。さて、実はこれは最も単純な機械学習の例となっている。</p>
<p>我々は、<span class="math inline">\(y = a x\)</span>というモデルを仮定し、<span class="math inline">\(N\)</span>個の観測値の組<span class="math inline">\((x_i, y_i)\)</span>を使ってモデルパラメータ<span class="math inline">\(a\)</span>を決定した。このパラメータを決定するプロセスを「学習」と呼ぶ。「学習」では、<span class="math inline">\(C(a)\)</span>を最小化するようにモデルのパラメータ<span class="math inline">\(a\)</span>を決定した。この最小化する関数を <strong>目的関数 (Cost Function)</strong>と呼ぶ。目的関数を最小化するために使われた観測データを「トレーニングデータ」と呼ぶ。トレーニングデータに対する誤差を<strong>訓練誤差</strong>と呼ぶ。</p>
<div class="figure">
<img src="fig/error.png" alt="訓練誤差と汎化誤差" />
<p class="caption">訓練誤差と汎化誤差</p>
</div>
<p>さて、我々の目的はあくまで「バネの伸び」という物理現象を記述することであって、「観測データを再現するモデルの構築」は、その手段に過ぎなかった。したがって、こうして得られた<span class="math inline">\(y = ax\)</span>というモデルは、未知の入力<span class="math inline">\(x\)</span>に対して、良い予想値<span class="math inline">\(y\)</span>を与えなくてはならない。トレーニングデータに含まれない入力<span class="math inline">\(x\)</span>に対して、我々が構築したモデルがどれくらい良いかを調べることを「テスト」と呼ぶ。</p>
<p>具体的には、モデルを決める時に使ったトレーニングデータとは別のデータセットを用意しておき、そのデータについてモデルがどれくらいよく予想できるかを確認する、ということがよく行われる。このような目的に使われるデータを「テストデータ」と呼び、テストデータに対する誤差を<strong>汎化誤差</strong>と呼ぶ。</p>
<p>訓練誤差は小さいのに、汎化誤差が大きい場合、トレーニングデータに最適化され過ぎており、応用が効かない「頭でっかち」なモデルになっていることを示唆する。これを <strong>過学習(overfitting)</strong> と呼ぶ。データの数に比べてモデルパラメータが多い時によく起きる。</p>
<div class="figure">
<img src="fig/overfitting.png" alt="訓練誤差・汎化誤差・過学習" />
<p class="caption">訓練誤差・汎化誤差・過学習</p>
</div>
<p>今回の講義で用いるTensorFlowをはじめとして、機械学習は高度に完成されたライブラリやフレームワークが多数存在する。その内部で用いられている理論やアルゴリズムは難しいものが多く、それらのフレームワークを「ブラックボックス」として用いるのはある程度やむを得ないところもある。しかし、機械学習に限らないことだが、基本的な概念、用語については、簡単な例でしっかり理解しておいた方が良い。「機械学習は最小二乗法のお化けのようなものだ」というと語弊があるのだが、学習、目的関数、訓練誤差、汎化誤差、過学習といった機械学習で頻出する単語のイメージを、中身がよくわかる単純な例、例えば線形モデルの最小二乗法で理解しておく、ということは非常に重要なことである。</p>
<p>機械学習に限らないことだが、「何かよくわからない概念が出てきたら、簡単な例で考えてみる」癖をつけておきたい。</p>
<h3 id="ganとは">GANとは</h3>
<p>通常よく使われる機械学習、例えば「植物の写真を見せて名前を答えるモデル」や「人間の写真を見せて年齢を推定するモデル」などでは、モデルは入力となるデータに対して何かしら「答え」を返すことが目的である。しかし、そういう分類や回帰ができるようになってくると、もっと難しい作業、例えば「有名な画家の絵を多数模写させることで、その画家のタッチでオリジナルの絵が書けるモデル」や、「テーマを伝えただけで映画やドラマの脚本を書けるモデル」などをやらせてみたくなるのが人情である。ここではそんな例として、GANを取り上げる。GAN (Generative Adversarial Networks)とは、直訳すると「敵対的生成ネットワーク」であり、二つのモデルを競わせることで画像を生成する手法である。</p>
<p>GANでは、GeneratorとDiscriminatorの二つのモデルを用意する。これらはよく「偽造者」「鑑定者」に例えられる。まず、本物のデータセット(例えば有名な画家の絵)を用意する。その後、ランダムに「本物のデータ」と「偽造者」が生成した「偽物のデータ」を「鑑定士」に見せ、それを本物か、偽物か判定させる。鑑定者から見れば、これは二値分類問題になっている。ラベルは「本物」か「偽物」である。鑑定者は大量に見せられるデータをどんどん鑑定することで「鑑定士」としての観察眼を磨いていく。</p>
<p>逆に、偽造者は、自分が提出したデータが「偽物」と見破られたら失敗、「本物」と鑑定されたら成功であり、そのフィードバックを受けながら「偽造者」としての腕を磨いていく。</p>
<div class="figure">
<img src="fig/gan.png" alt="GANの概念図" />
<p class="caption">GANの概念図</p>
</div>
<p>こうして「偽造者」と「鑑定者」がお互いに切磋琢磨しながら学習していくと、最終的に「本物と見紛うばかりのデータを生成できる偽造者が誕生するだろう」というのがGANの要諦である。今回の課題では、適当なデータセットを用意し、偽造者と鑑定者を学習させることで、最終的に偽造者が用意したデータセットを真似た絵を生成できるようになるプロセスを観察しよう。</p>
<h2 id="簡単な機械学習課題">簡単な機械学習：課題</h2>
<h3 id="課題1回帰">課題1：回帰</h3>
<p>TODO</p>
<h3 id="課題2gan">課題2：GAN</h3>
<p>敵対的生成ネットワーク、GAN (Generative Adversarial Networks)を体験してみよう。これは、偽造者(Generator)と鑑定者(Discriminator)がお互いに切磋琢磨させることで、偽造者に本物そっくりの画像を生成させるようにする手法である。</p>
<p>新しいノートブックを開き<code>gan.ipynb</code>として保存せよ。</p>
<h4 id="tensorflowのインストール">1. TensorFlowのインストール</h4>
<p>Google ColabではデフォルトでTensorFlowが使えるが、今回はやや古いバージョンを使いたいので、バージョンを指定してインストールをする。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python"><span class="op">%</span>tensorflow_version <span class="fl">1.</span>x
<span class="op">!</span>pip install tensorflow<span class="op">==</span><span class="fl">1.13</span>.<span class="dv">1</span></code></pre></div>
<p>最初の<code>%</code>から始まる行はマジックコメントと呼ばれ、Google Colabに「これからバージョン1.0系を使うよ」という指示をする。</p>
<pre class="txt"><code>Successfully installed mock-3.0.5 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0</code></pre>
<p>と表示されれば正しくインストールされている。</p>
<h4 id="サンプルプログラムのダウンロード">2. サンプルプログラムのダウンロード</h4>
<p>GANのプログラムは、簡単なものでもそれなりに長いコードを記述する必要がある。今回は既に入力されたプログラムをダウンロードしよう。以下を実行せよ。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python"><span class="op">!</span>wget https:<span class="op">//</span>kaityo256.github.io<span class="op">/</span>python_zero<span class="op">/</span>gan<span class="op">/</span>gan_test.py</code></pre></div>
<p><code>‘gan_test.py’ saved</code>と表示されればダウンロード完了である。</p>
<h4 id="インポート">3. インポート</h4>
<p>先程ダウンロードしたプログラムをインポートしよう。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python"><span class="im">import</span> gan_test</code></pre></div>
<p>実行時に多数の<code>FutureWarning</code>が出るが、気にしなくて良い。これでGANが使えるようになった。</p>
<h4 id="データのダウンロード">4. データのダウンロード</h4>
<p>GANでは、まず「正解の画像」をデータセットとして与える必要がある。偽造者は、その画像に似せて絵を描いていく。逆に、与えるデータによって「好きな画家」を模写できるように学習させることができる。本講義では、三つのデータセットを用意した。</p>
<ul>
<li><code>mnist.tfrecord</code> 手書きの数字(MNIST)</li>
<li><code>fontawesome.tfrecord</code> Font Awesomeというフォントのシンボルアイコン10種類</li>
<li><code>hiragana.tfrecord</code> ひらがなすべて(IPAゴシックフォント)</li>
</ul>
<p>上記のうち、好きなものを一つ選んで<code>TRAIN_DATA</code>とし、ダウンロードすること。数字は学習が容易だが、ひらがなは難しく、シンボルはその中間、といった特徴がある。</p>
<p>以下は手書きの数字(MNIST)を選んだ場合の例である。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python">TRAIN_DATA <span class="op">=</span> <span class="st">&quot;mnist.tfrecord&quot;</span>
url<span class="op">=</span><span class="st">&quot;https://kaityo256.github.io/python_zero/gan/&quot;</span>
<span class="bu">file</span><span class="op">=</span>url<span class="op">+</span>TRAIN_DATA
<span class="op">!</span>wget $file</code></pre></div>
<p><code>‘mnist.tfrecord’ saved</code>など、自分が選んだファイル名が表示されればダウンロード完了である。</p>
<h4 id="ganの実行">5. GANの実行</h4>
<p>ではいよいよGANの実行をしてみよう。以下を実行せよ。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python">gan_test.run_gan(TRAIN_DATA)</code></pre></div>
<p>最初に</p>
<pre class="txt"><code>WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.</code></pre>
<p>といった警告が出るが、気にしないで良い。</p>
<p>画面には、数十秒ごとに偽造者が作成した画像が表示されていく。最初は完全なノイズにしか見えなかった画像が、学習が進むにつれて偽造者が「腕を上げていく」様子が見えるであろう。学習が終わったら(もしくは途中で止めて)、別の画像でも学習させてみよ。</p>
<h2 id="余談aiに悪意はあるか">余談：AIに悪意はあるか</h2>
<p>AIに意識があるか、という問題は難しい。個人的には「AIはそのうち意識を持つ」と信じているが、現時点では「まだソフトウェアなんだな」と思う時と「人間と同じ問題を抱えているのでは」と思う時の両方がある。</p>
<p>「あ、AIはただのソフトウェアなんだな」と思う例の一つは画像認識である。「犬」「猫」「羊」などのラベルがついた画像を事前に学習させておくことで、写真に何が写っているかを認識するAIを作るものだ。一見するとこのAIは写真に写るものを正しく認識しているように見えるが、何もいない草原に「羊がいる」と判断してしまう。「羊」のラベルがついた画像のほとんどが草原であったため、「草原＝羊」と認識してしまったのだ。同様な例に「ハスキーと狼問題」がある。シベリアン・ハスキーは狼に似た犬種であるが、そのハスキーと狼を見分けるAIを作ったところ、実は犬ではなく「背景に雪があるかどうか」で判断していることがあった。</p>
<p>多くの場合、こうした画像認識の失敗は笑い話で済むが、差別問題がからむとやっかいなことになる。2015年、Googleは、写真管理アプリGoogle Photosをリリースしたが、そのアプリには写真に写っているものを認識し、ラベル付けする機能があった。しかし、黒人女性が写る写真に「ゴリラ」とタグ付けしてしまい、Googleが謝罪する事態となった。これについては「差別的な人間が黒人に『ゴリラ』という差別的なタグをつけていたものを学習したせいだ」という噂も流れたが、どうやら純粋に「白人以外」のデータが足りずに、素で間違ったようだ。他にも、やはり黒人女性を「猿(Apes)」と認識してしまうことがわかった。結局Googleは根本解決ができず、「ゴリラ、猿、チンパンジー」といったラベルを禁止ワードにすることで対処することになった。</p>
<p>Google翻訳がジェンダーバイアスを持つことも知られている。例えば現時点(2019年12月4日現在)では、「<strong>医者</strong> は旅行先でカバンを忘れてきた。」は「The doctor has forgotten <strong>his</strong> bag at the travel destination.」と訳すが、「<strong>看護師</strong> は旅行先で……」とすると「The nurse has forgotten <strong>her</strong> bag when traveling.」と訳す。Google翻訳は多くの翻訳例を通じて学習したモデルを用いているが、そのデータ上で「Docter」が「his」と、「Nurse」が「her」と一緒に用いらていれることが多かったのだと思われる。</p>
<p>Google Photosの問題は「学習データに白人が多く黒人が少なかったため」に起きたことであり、Google翻訳の問題は学習用データを通じて「医者は男性が多く、看護師は女性が多い」という「偏見」も一緒に学習してしまったために起きたことだ。現時点では「AI」に罪はなく、「AIの学習過程で人間持つの差別や偏見が注入された」と認識されているが、そもそも学習で偏った情報に触れて偏見を身につけてしまうという過程は人間と全く同じである。既に自らの過ちをAIのせいにしている人も出現しており、そのうちAIが高度に発展した場合、我々はAIそのものに悪意や偏見を感じるようになるのかもしれない。</p>
<ul>
<li>「Notes on AI Bias」<a href="https://www.ben-evans.com/benedictevans/2019/4/15/notes-on-ai-bias" class="uri">https://www.ben-evans.com/benedictevans/2019/4/15/notes-on-ai-bias</a></li>
</ul>
</article>
</body>
</html>
