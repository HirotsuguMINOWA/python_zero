<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>

<style>
    .btn-square {
      display: inline-block;
      padding: 0.5em 0.5em;
      text-decoration: none;
      background: #668ad8;
      color: #FFF;
      border-bottom: solid 4px #626295;
      border-radius: 5px;
    }

    .btn-square:active {
      -webkit-transform: translateY(4px);
      transform: translateY(4px);
      border-bottom: none;
    }
  .markdown-body {
    box-sizing: border-box;
    min-width: 200px;
    max-width: 980px;
    margin: 0 auto;
    padding: 45px;
  }
  p.caption{
    display:none;
  }
  img {width: 100%}

  @media (max-width: 767px) {
    .markdown-body {
      padding: 15px;
    }
  }
</style>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://kaityo256.github.io/python_zero/github-markdown.css" type="text/css" />
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
<link href="https://use.fontawesome.com/releases/v5.6.1/css/all.css" rel="stylesheet">
</head>
<body>
<article class="markdown-body">
<h1 id="簡単な機械学習"><a href="https://kaityo256.github.io/python_zero/gan/">簡単な機械学習</a></h1>
<p><a href="../index.html">[Up]</a> <a href="https://github.com/kaityo256/python_zero">[Repository]</a></p>
<h2 id="本講の目的">本講の目的</h2>
<ul>
<li>機械学習の概要について学ぶ</li>
<li>GANを体験する</li>
<li>余談：心理的安全性について</li>
</ul>
<h2 id="機械学習とは">機械学習とは</h2>
<p>昨今、「機械学習」「ディープラーニング」「AI」といった言葉をよく聞く。Googleによる機械学習のフレームワーク「TensorFlow」や、PFNによる「Chainer」などがPythonで記述されていることもあり、機械学習をする上でPythonが事実上の共通語になりつつある。機械学習による派手な結果を目にすることも多いだろう。せっかく本講義でPythonを学んだのであるから、最後は機械学習を体験してみよう。今回は、ざっと機械学習の概要について触れてから、機械学習で注目されている技術の一つ、GANによる画像生成を体験してみる。</p>
<h3 id="機械学習の種類">機械学習の種類</h3>
<p>一口に「機械学習」と言っても、機械学習がカバーする範囲は広い。現在も様々な技術が提案されているため、その全てを厳密に分類するのは難しいが、よく言われるのは以下の三種類の分類である。</p>
<ol style="list-style-type: decimal">
<li>教師あり学習</li>
<li>教師なし学習</li>
<li>強化学習</li>
</ol>
<p><strong>教師あり学習(Supervised Learning)</strong> とは、「問題と解答のセット」を与えて、それで学習させる方法である。例えば、予め大量の写真を用意し、それぞれに「ネコ」や「イヌ」といったラベルをつけておく。それを学習させることで、「学習に用いたデータセットに含まれていない、初めて見る写真」に対しても正しく「ネコ」や「イヌ」と判定できるようにさせるのが典型的な教師あり学習である。</p>
<p><strong>教師なし学習(Unsupervised Learning)</strong> とは、データだけを与えて、データを分類したり、似ているものを探したりさせる方法である。例えば物品の売上データを解析し、「ある商品Aを購入した人は、次は商品Bを購入する可能性が高い」といった関係を見つければ、商品Aを購入した人に「Bはいかがでしょうか？」と勧めることができ、売上向上につながる。オンラインショップなどでよく見る「この商品を買った人はこんな商品も買っています」というアレである。</p>
<p><strong>強化学習(Reinforcement Learning)</strong> とは、何かエージェントに行動をさせて、その結果として報酬を与えることで、「うまく」行動できるように学習させていく手法である。典型的な応用例はチェスや囲碁、将棋などのボードゲームのAIであろう。ある局面において、多数ある合法手の中から「次の一手」を選ばなければならない。この時、とりあえず(現在の知識で)適当に指してみて、勝負が決まってから振り返り、「最終的に勝利につながった手」に正の報酬を、「敗北につながった手」に負の報酬を与えることで、それぞれの局面において「これは良い手だった」「これは悪手だった」と学習していく。</p>
<p>これらはどれも面白く、それぞれ奥が深いのだが、ここでは教師あり学習に注目する。</p>
<p>「教師あり学習」が扱う問題は、さらに「分類問題」と「回帰問題」にわけることができる。分類問題とは、入力に対して有限のラベルのどれかを当てる問題である。例えば「ネコ」「イヌ」「ゾウ」「パンダ」のどれかが写っている写真を見せられ、何が写っているかを答えるのが典型的な分類問題である。特に、ラベルが「Yes」か「No」の二種類である時、これを二値分類問題と呼ぶ。回帰問題とは、入力に対して何か連続な値を返す問題である。例えば家の広さ、築年数、駅からの距離や周りの条件等から家賃を推定するのが典型的な回帰問題である。</p>
<h3 id="学習と最適化">学習と最適化</h3>
<p>機械学習では、よく「学習」という言葉が出てくる。学習とは、ある量を最適化することだ。その最適化の簡単な例として、線形回帰を見てよう。</p>
<p>回帰とは、何かしらの入力<span class="math inline">\(x\)</span>に対して、出力<span class="math inline">\(y\)</span>が得られる時、その間の関係<span class="math inline">\(y = f(x)\)</span>を推定する問題である。例えば片方を固定されたバネに荷重をかけ、どのくらい伸びるかを調べる実験を考える。この場合の入力<span class="math inline">\(x\)</span>は荷重、出力<span class="math inline">\(y\)</span>はバネの伸びである。とりあえずいくつか重りを乗せてみて、荷重と伸びの観測値をグラフにプロットしてみたら以下のようになったとしよう。</p>
<div class="figure">
<img src="fig/regression.png" alt="バネの伸びと荷重の関係" />
<p class="caption">バネの伸びと荷重の関係</p>
</div>
<p>ここから、バネ定数を推定するには最小二乗法を使えば良いことは知っているであろうが、簡単におさらいしておこう。いま、<span class="math inline">\(N\)</span>回異なる荷重をかける実験を行い、荷重とバネの伸びの観測値の組<span class="math inline">\((x_i, y_i)\)</span>が得られたとする。さて、フックの法則から<span class="math inline">\(y = a x\)</span>が予想される。<span class="math inline">\(x_i\)</span>の荷重がかかった時、このモデルによる予想値は<span class="math inline">\(a x_i\)</span>だが、観測値は<span class="math inline">\(y_i\)</span>だ。そのズレ<span class="math inline">\(y_i - a x_i\)</span>を残差と呼ぶ。この残差の二乗和は<span class="math inline">\(a\)</span>の関数であり、以下のように表すことができる。</p>
<p><span class="math display">\[
C(a) = \sum_i^N (a x_i - y_i)^2
\]</span></p>
<p><span class="math inline">\(C(a)\)</span>はモデルと観測値の誤差を表している。<span class="math inline">\(a\)</span>が大きすぎても小さすぎても<span class="math inline">\(C(a)\)</span>は大きくなるので、どこかに最適な<span class="math inline">\(a\)</span>があるだろう。<span class="math inline">\(C(a)\)</span>を最小化するような<span class="math inline">\(a\)</span>の値は、<span class="math inline">\(C(a)\)</span>を<span class="math inline">\(a\)</span>で微分してゼロになるような点であるはずだ。微分してみよう。</p>
<p><span class="math display">\[
\frac{dC}{da} = \sum_i^N (2 a x_i^2 - 2a x_i y_i) = 0
\]</span></p>
<p>これを<span class="math inline">\(a\)</span>について解けば、</p>
<p><span class="math display">\[
a = \frac{\sum_i^N x_i y_i}{\sum_i^N x_i^2}
\]</span></p>
<p>を得る。さて、実はこれは最も単純な機械学習の例となっている。</p>
<p>我々は、<span class="math inline">\(y = a x\)</span>というモデルを仮定し、<span class="math inline">\(N\)</span>個の観測値の組<span class="math inline">\((x_i, y_i)\)</span>を使ってモデルパラメータ<span class="math inline">\(a\)</span>を決定した。このパラメータを決定するプロセスを「学習」と呼ぶ。「学習」では、<span class="math inline">\(C(a)\)</span>を最小化するようにモデルのパラメータ<span class="math inline">\(a\)</span>を決定した。この最小化する関数を <strong>目的関数 (Cost Function)</strong>と呼ぶ。目的関数を最小化するために使われた観測データを「トレーニングデータ」と呼ぶ。トレーニングデータに対する誤差を<strong>訓練誤差</strong>と呼ぶ。</p>
<div class="figure">
<img src="fig/error.png" alt="訓練誤差と汎化誤差" />
<p class="caption">訓練誤差と汎化誤差</p>
</div>
<p>さて、我々の目的はあくまで「バネの伸び」という物理現象を記述することであって、「観測データを再現するモデルの構築」は、その手段に過ぎなかった。したがって、こうして得られた<span class="math inline">\(y = ax\)</span>というモデルは、未知の入力<span class="math inline">\(x\)</span>に対して、良い予想値<span class="math inline">\(y\)</span>を与えなくてはならない。トレーニングデータに含まれない入力<span class="math inline">\(x\)</span>に対して、我々が構築したモデルがどれくらい良いかを調べることを「テスト」と呼ぶ。</p>
<p>具体的には、モデルを決める時に使ったトレーニングデータとは別のデータセットを用意しておき、そのデータについてモデルがどれくらいよく予想できるかを確認する、ということがよく行われる。このような目的に使われるデータを「テストデータ」と呼び、テストデータに対する誤差を<strong>汎化誤差</strong>と呼ぶ。</p>
<p>訓練誤差は小さいのに、汎化誤差が大きい場合、トレーニングデータに最適化され過ぎており、応用が効かない「頭でっかち」なモデルになっていることを示唆する。これを <strong>過学習(overfitting)</strong> と呼ぶ。データの数に比べてモデルパラメータが多い時によく起きる。</p>
<div class="figure">
<img src="fig/overfitting.png" alt="訓練誤差・汎化誤差・過学習" />
<p class="caption">訓練誤差・汎化誤差・過学習</p>
</div>
<p>今回の講義で用いるTensorFlowをはじめとして、機械学習は高度に完成されたライブラリやフレームワークが多数存在する。その内部で用いられている理論やアルゴリズムは難しいものが多く、それらのフレームワークを「ブラックボックス」として用いるのはある程度やむを得ないところもある。しかし、機械学習に限らないことだが、基本的な概念、用語については、簡単な例でしっかり理解しておいた方が良い。「機械学習は最小二乗法のお化けのようなものだ」というと語弊があるのだが、学習、目的関数、訓練誤差、汎化誤差、過学習といった機械学習で頻出する単語のイメージを、中身がよくわかる単純な例、例えば線形モデルの最小二乗法で理解しておく、ということは非常に重要なことである。</p>
<p>機械学習に限らないことだが、「何かよくわからない概念が出てきたら、簡単な例で考えてみる」癖をつけておきたい。</p>
<h3 id="ganとは">GANとは</h3>
<p>通常よく使われる機械学習、例えば「植物の写真を見せて名前を答えるモデル」や「人間の写真を見せて年齢を推定するモデル」などでは、モデルは入力となるデータに対して何かしら「答え」を返すことが目的である。しかし、そういう分類や回帰ができるようになってくると、もっと難しい作業、例えば「有名な画家の絵を多数模写させることで、その画家のタッチでオリジナルの絵が書けるモデル」や、「テーマを伝えただけで映画やドラマの脚本を書けるモデル」などをやらせてみたくなるのが人情である。ここではそんな例として、GANを取り上げる。GAN (Generative Adversarial Networks)とは、直訳すると「敵対的生成ネットワーク」であり、二つのモデルを競わせることで画像を生成する手法である。</p>
<p>GANでは、GeneratorとDiscriminatorの二つのモデルを用意する。これらはよく「偽造者」「鑑定者」に例えられる。まず、本物のデータセット(例えば有名な画家の絵)を用意する。その後、ランダムに「本物のデータ」と「偽造者」が生成した「偽物のデータ」を「鑑定士」に見せ、それを本物か、偽物か判定させる。鑑定者から見れば、これは二値分類問題になっている。ラベルは「本物」か「偽物」である。鑑定者は大量に見せられるデータをどんどん鑑定することで「鑑定士」としての観察眼を磨いていく。</p>
<p>逆に、偽造者は、自分が提出したデータが「偽物」と見破られたら失敗、「本物」と鑑定されたら成功であり、そのフィードバックを受けながら「偽造者」としての腕を磨いていく。</p>
<div class="figure">
<img src="fig/gan.png" alt="GANの概念図" />
<p class="caption">GANの概念図</p>
</div>
<p>こうして「偽造者」と「鑑定者」がお互いに切磋琢磨しながら学習していくと、最終的に「本物と見紛うばかりのデータを生成できる偽造者が誕生するだろう」というのがGANの要諦である。今回の課題では、適当なデータセットを用意し、偽造者と鑑定者を学習させることで、最終的に偽造者が用意したデータセットを真似た絵を生成できるようになるプロセスを観察しよう。</p>
<h1 id="簡単な機械学習課題">簡単な機械学習：課題</h1>
<h2 id="gan">GAN</h2>
<p>Googleによる機械学習のライブラリ、Tensorflowを使ってGAN (Generative Adversarial Networks)を組んでみよう。それなりにコード量があるので、間違いないように注意して入力すること。</p>
<h3 id="課題1-ganの実行テスト">課題1: GANの実行テスト</h3>
<p>新しいノートブックを開き、<code>gan.ipynb</code>という名前で保存せよ。</p>
<h4 id="import">1. import</h4>
<p>最初のセルで必要なモジュールをimportしよう。ついでにTensorFlowの警告を減らす設定をしておく。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python"><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt
<span class="im">import</span> numpy <span class="im">as</span> np
<span class="im">import</span> tensorflow <span class="im">as</span> tf
tf.logging.set_verbosity(tf.logging.ERROR)</code></pre></div>
<h4 id="宣言">2. 宣言</h4>
<p>2つ目のセルで今後使うオブジェクトやパラメータの宣言を行う。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python">tfgan <span class="op">=</span> tf.contrib.gan
layers <span class="op">=</span> tf.contrib.layers
framework <span class="op">=</span> tf.contrib.framework
slim <span class="op">=</span> tf.contrib.slim
dataprovider <span class="op">=</span> slim.dataset_data_provider.DatasetDataProvider
BATCH_SIZE <span class="op">=</span> <span class="dv">32</span></code></pre></div>
<p>「WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.」といったTensorFlowからの警告が出るが気にしなくてよい。</p>
<h4 id="generatorの宣言">3. Generatorの宣言</h4>
<p>Generator(偽造者)の宣言を行う。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python"><span class="kw">def</span> generator_fn(noise, weight_decay<span class="op">=</span><span class="fl">2.5e-5</span>, is_training<span class="op">=</span><span class="va">True</span>):
    f1 <span class="op">=</span> framework.arg_scope(
        [layers.fully_connected, layers.conv2d_transpose],
        activation_fn<span class="op">=</span>tf.nn.relu,
        normalizer_fn<span class="op">=</span>layers.batch_norm,
        weights_regularizer<span class="op">=</span>layers.l2_regularizer(weight_decay))
    f2 <span class="op">=</span> framework.arg_scope(
        [layers.batch_norm],
        is_training<span class="op">=</span>is_training,
        zero_debias_moving_mean<span class="op">=</span><span class="va">True</span>)
    <span class="cf">with</span> f1, f2:
        net <span class="op">=</span> layers.fully_connected(noise, <span class="dv">1024</span>)
        net <span class="op">=</span> layers.fully_connected(net, <span class="dv">7</span> <span class="op">*</span> <span class="dv">7</span> <span class="op">*</span> <span class="dv">256</span>)
        net <span class="op">=</span> tf.reshape(net, [<span class="op">-</span><span class="dv">1</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">256</span>])
        net <span class="op">=</span> layers.conv2d_transpose(net, <span class="dv">64</span>, [<span class="dv">4</span>, <span class="dv">4</span>], stride<span class="op">=</span><span class="dv">2</span>)
        net <span class="op">=</span> layers.conv2d_transpose(net, <span class="dv">32</span>, [<span class="dv">4</span>, <span class="dv">4</span>], stride<span class="op">=</span><span class="dv">2</span>)
        net <span class="op">=</span> layers.conv2d(net, <span class="dv">1</span>, <span class="dv">4</span>, activation_fn<span class="op">=</span>tf.tanh)
        <span class="cf">return</span> net</code></pre></div>
<h4 id="discriminatorの宣言">4. Discriminatorの宣言</h4>
<p>Discriminator(鑑定者)の宣言を行う。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python"><span class="kw">def</span> discriminator_fn(img, _, weight_decay<span class="op">=</span><span class="fl">2.5e-5</span>, is_training<span class="op">=</span><span class="va">True</span>):
    <span class="cf">with</span> framework.arg_scope(
            [layers.conv2d, layers.fully_connected],
            activation_fn<span class="op">=</span>(<span class="kw">lambda</span> n: tf.nn.leaky_relu(n, alpha<span class="op">=</span><span class="fl">0.01</span>)),
            weights_regularizer<span class="op">=</span>layers.l2_regularizer(weight_decay),
            biases_regularizer<span class="op">=</span>layers.l2_regularizer(weight_decay)):
        net <span class="op">=</span> layers.conv2d(img, <span class="dv">64</span>, [<span class="dv">4</span>, <span class="dv">4</span>], stride<span class="op">=</span><span class="dv">2</span>)
        net <span class="op">=</span> layers.conv2d(net, <span class="dv">128</span>, [<span class="dv">4</span>, <span class="dv">4</span>], stride<span class="op">=</span><span class="dv">2</span>)
        net <span class="op">=</span> layers.flatten(net)
        <span class="cf">with</span> framework.arg_scope([layers.batch_norm], is_training<span class="op">=</span>is_training):
            net <span class="op">=</span> layers.fully_connected(
                net, <span class="dv">1024</span>, normalizer_fn<span class="op">=</span>layers.batch_norm)
        <span class="cf">return</span> layers.linear(net, <span class="dv">1</span>)</code></pre></div>
<h4 id="データセットの準備">5. データセットの準備</h4>
<p>「本物」のデータを供給する関数を定義する。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python"><span class="kw">def</span> provide_data(source, batch_size):
    keys_to_features <span class="op">=</span> {
        <span class="st">&#39;image/encoded&#39;</span>: tf.FixedLenFeature((), tf.string, default_value<span class="op">=</span><span class="st">&#39;&#39;</span>),
        <span class="st">&#39;image/format&#39;</span>: tf.FixedLenFeature((), tf.string, default_value<span class="op">=</span><span class="st">&#39;raw&#39;</span>),
    }
    datanum <span class="op">=</span> <span class="bu">sum</span>(<span class="dv">1</span> <span class="cf">for</span> _ <span class="kw">in</span> tf.python_io.tf_record_iterator(source))
    items_to_handlers <span class="op">=</span> {
        <span class="st">&#39;image&#39;</span>: slim.tfexample_decoder.Image(shape<span class="op">=</span>[<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>], channels<span class="op">=</span><span class="dv">1</span>),
    }
    decoder <span class="op">=</span> slim.tfexample_decoder.TFExampleDecoder(
        keys_to_features, items_to_handlers)
    reader <span class="op">=</span> tf.TFRecordReader
    dataset <span class="op">=</span> slim.dataset.Dataset(source, reader, decoder, datanum, <span class="va">None</span>)
    provider <span class="op">=</span> dataprovider(dataset, shuffle<span class="op">=</span><span class="va">True</span>)
    image, <span class="op">=</span> provider.get([<span class="st">&#39;image&#39;</span>])
    image <span class="op">=</span> (tf.cast(image, tf.float32) <span class="op">-</span> <span class="fl">128.0</span>) <span class="op">/</span> <span class="fl">128.0</span>
    images <span class="op">=</span> tf.train.batch([image], batch_size<span class="op">=</span>batch_size)
    <span class="cf">return</span> images</code></pre></div>
<h4 id="データセットのダウンロード">6. データセットのダウンロード</h4>
<p>学習に用いるデータセットをダウンロードしよう。データセットは以下の三種類を用意してある。</p>
<ul>
<li><code>mnist.tfrecord</code> 手書きの数字(MNIST)</li>
<li><code>hiragana.tfrecord</code> ひらがなすべて(IPAゴシックフォント)</li>
<li><code>fontawesome.tfrecord</code> Font Awesomeというフォントのシンボルアイコン10種類</li>
</ul>
<p>上記のうち、好きなものを一つ選んで<code>TRAIN_DATA</code>とすること。以下はMNISTを選んだ場合の例である。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python">TRAIN_DATA <span class="op">=</span> <span class="st">&quot;mnist.tfrecord&quot;</span>
url<span class="op">=</span><span class="st">&quot;https://kaityo256.github.io/simple_tfgan/dataset/&quot;</span>
<span class="bu">file</span><span class="op">=</span>url<span class="op">+</span>TRAIN_DATA
<span class="op">!</span>wget $file</code></pre></div>
<p>上記を実行すると、ファイルがダウンロードされる。最後に以下のような表示がされたら成功である。</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="ex">2019-05-31</span> 08:03:55 (138 MB/s) <span class="ex">-</span> ‘mnist.tfrecord’ saved [20852051/20852051]</code></pre></div>
<h4 id="初期化">7. 初期化</h4>
<p>TensorFlowを初期化し、データをバッチに変換する。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python">tf.reset_default_graph()
<span class="cf">with</span> tf.device(<span class="st">&#39;/cpu:0&#39;</span>):
    real_images <span class="op">=</span> provide_data(TRAIN_DATA, BATCH_SIZE)</code></pre></div>
<h4 id="ganの宣言">8. GANの宣言</h4>
<p>これまで宣言した「偽造者(Generator)」と「鑑定者(Discriminator)」を競争させるGANを宣言する。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python">gan_model <span class="op">=</span> tfgan.gan_model(
    generator_fn,
    discriminator_fn,
    real_data<span class="op">=</span>real_images,
    generator_inputs<span class="op">=</span>tf.random_normal([BATCH_SIZE, <span class="dv">64</span>]))

improved_wgan_loss <span class="op">=</span> tfgan.gan_loss(
    gan_model,
    generator_loss_fn<span class="op">=</span>tfgan.losses.wasserstein_generator_loss,
    discriminator_loss_fn<span class="op">=</span>tfgan.losses.wasserstein_discriminator_loss,
    gradient_penalty_weight<span class="op">=</span><span class="fl">1.0</span>)

generator_optimizer <span class="op">=</span> tf.train.AdamOptimizer(<span class="fl">0.001</span>, beta1<span class="op">=</span><span class="fl">0.5</span>)
discriminator_optimizer <span class="op">=</span> tf.train.AdamOptimizer(<span class="fl">0.0001</span>, beta1<span class="op">=</span><span class="fl">0.5</span>)
gan_train_ops <span class="op">=</span> tfgan.gan_train_ops(
    gan_model,
    improved_wgan_loss,
    generator_optimizer,
    discriminator_optimizer)

<span class="cf">with</span> tf.variable_scope(<span class="st">&#39;Generator&#39;</span>, reuse<span class="op">=</span><span class="va">True</span>):
    eval_images <span class="op">=</span> gan_model.generator_fn(
        tf.random_normal([<span class="dv">500</span>, <span class="dv">64</span>]),
        is_training<span class="op">=</span><span class="va">False</span>)

visualizer <span class="op">=</span> tfgan.<span class="bu">eval</span>.image_reshaper(eval_images[:<span class="dv">20</span>, ...], num_cols<span class="op">=</span><span class="dv">10</span>)

train_step_fn <span class="op">=</span> tfgan.get_sequential_train_steps()
global_step <span class="op">=</span> tf.train.get_or_create_global_step()</code></pre></div>
<h4 id="ganの実行">9. GANの実行</h4>
<p>それではいよいよGANを実行してみよう。とりあえずテストとして200回ほど学習させる。25回に一度、Generatorが生成する画像を表示させている。ここまで正しく入力できていれば、学習過程が可視化されていくはずである。</p>
<div class="sourceCode"><pre class="sourceCode py"><code class="sourceCode python">TOTAL_STEPS <span class="op">=</span> <span class="dv">201</span>
INTERVAL <span class="op">=</span> <span class="dv">25</span>
<span class="cf">with</span> tf.train.SingularMonitoredSession() <span class="im">as</span> sess:
    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(TOTAL_STEPS):
        train_step_fn(sess, gan_train_ops, global_step,
                        train_step_kwargs<span class="op">=</span>{})
        <span class="cf">if</span> i <span class="op">%</span> INTERVAL <span class="op">==</span> <span class="dv">0</span>:
            digits_np <span class="op">=</span> sess.run([visualizer])
            plt.axis(<span class="st">&#39;off&#39;</span>)
            plt.imshow(np.squeeze(digits_np), cmap<span class="op">=</span><span class="st">&#39;gray&#39;</span>)
            plt.show()</code></pre></div>
<p>Generatorが生成する画像は、最初は単なるノイズだが、徐々に「それっぽい」画像になっていくのがわかるであろう。</p>
<h3 id="課題2-別のデータセットのテスト">課題2: 別のデータセットのテスト</h3>
<p>うまくいったら、他のデータセットも試してみよ。データをダウンロードするセル(6つ目)で<code>TRAIN_DATA</code>を書き換え、そこから順番にセルを再実行すれば、別のデータセットで学習をするはずである。もしくは，<code>TOTAL_STEPS</code>をもう少し長くして、学習結果がどうなるを見ても良い。MNISTやFont Awesomeなら1000ステップもあればそれなりの画像となるが、ひらがなは種類が多いため、学習に苦しむようである。その観察結果を報告せよ。</p>
<h2 id="余談心理的安全性について">余談：心理的安全性について</h2>
<p>例えば子育てをしている人が、ブログなりSNSなりで子育ての経験を書いているとしよう。子育てをしていると、たまに「ヒヤッ」とすることがある。いつの間にか子供が危険なもので遊んでいた、危険なものの近くにいた、ふと目を離しスキにいなくなった……そんな「ヒヤッ」としたり「ハッ」としたりする、重大事故一歩手前の状態を俗に「ヒヤリハット」と呼ぶ。そんな「ヒヤリハット」をネットに流した時の、まわりの人の反応を想像してみてほしい。「そんな危険な目に合わせるなんて子供がかわいそう」「○○に気をつけないなんて親として失格」という非難のコメントが付きそうな気がするであろう。実際、子供がらみの事件のニュースサイトのコメント欄で親を責める声はよく見かける。さて、「ヒヤリハット」を公開し、非難された親はどうするか。もちろん「次回は気をつけよう」と思うであろうが、それ以上に「子育てのヒヤリハットはネットに公開してはいけない」と学ぶであろう。そして、そのブログなりSNSの読者が「うちも気をつけよう」と思うような情報の共有機会が失われることになる。</p>
<p>全く同様なことが会社組織などで起きる。工事現場で危険な目にあったことを何気なく上長に伝えたら、「危ないだろ！」と叱責されたとしよう。その部下はおそらく次から危険な事例を報告しなくなるだろう。1つの重大事故の影には、多数の「ヒヤリハット」が隠れているという。頻繁に「ヒヤリハット」が発生するということは、安全性になんらかの根本的な問題があるという重要なサインなのであるが、それを言い出しづらい雰囲気の中では「危険の芽」は黙殺され、そのうち重大事故につながってしまう。</p>
<p>このような「ネガティブな報告」をしづらい雰囲気がまずいことは感覚的にわかるであろう。逆に、「ネガティブな報告をしても責められない、初歩的な質問をしても馬鹿にされない」状態を「心理的安全性が保たれた状態」と呼ぶ。心理的安全性(Psychological Safety)は、Googleの働き方の研究(Project Aristotle)の報告から広まったものだ。</p>
<p>KPIという言葉を聞いたことがあるだろう。Key Performance Indicatorの略で、要するに数値目標のことだ。心理的安全性なしにKPIの数値だけに着目すると、必ずまずい状態になる。例えば、あるソフトウェア開発グループでは、「バグゼロ」を目指し、バグの報告が多い部署は「目標達成度が低い」とみなされた。すると、当然のことながらバグを見つけてもそれはバグとして報告されず、例えば「機能追加の要望」などとして処理されるようになった。数字の上では全体的に「報告される」バグの数は激減したが、これが望ましい状態ではないことは明らかであろう。逆に、ある工場では、製品の完成チェック時に必ず一定数以上の問題を見つけることを強制した。するとどうなるか。品質管理部は、たとえほとんど問題がない製品でも、言いがかりのような問題を見つけて報告するようになった。それに対抗するように、工場ではわざと目に付きやすい問題点を残すようになった。「バグが許されない職場」は「バグが報告されない職場」になり、「問題を必ず見つける職場」では「問題を必ず作る職場」になってしまった。</p>
<p>共通するのは心理的安全性であり、もっと言えばチームの目的意識の共有である。我々は本質的なバグの数を減らしたいのであって、バグの報告を減らしてはならない。「心理的安全性なしにKPIのみを重視すると、必ず数値ハックされる」ということは心に留めておきたい。</p>
<p>参考URL</p>
<ul>
<li>re:Work - The five keys to a successful Google team</li>
<li><a href="https://rework.withgoogle.com/blog/five-keys-to-a-successful-google-team/" class="uri">https://rework.withgoogle.com/blog/five-keys-to-a-successful-google-team/</a></li>
<li>チャットコミュニケーションの問題と心理的安全性の課題</li>
<li><a href="https://www.slideshare.net/TokorotenNakayama/eof2019/" class="uri">https://www.slideshare.net/TokorotenNakayama/eof2019/</a></li>
</ul>
</article>
</body>
</html>
